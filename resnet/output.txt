nohup: ignoring input
/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
{'boxes': tensor([[ 98.7109, 115.1719,  99.2578, 118.4531],
        [218.0391, 116.1016, 218.8047, 120.1484]]), 'labels': tensor([1, 1]), 'orig_size': tensor([ 128, 1024], dtype=torch.int32)}
♫Training Montage♫ by Vince DiCola starts playing...
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:40<1:07:23, 40.85s/it]  2%|▏         | 2/100 [01:21<1:06:28, 40.70s/it]  3%|▎         | 3/100 [02:02<1:05:42, 40.64s/it]  4%|▍         | 4/100 [02:42<1:04:59, 40.62s/it]  5%|▌         | 5/100 [03:23<1:04:18, 40.62s/it]  6%|▌         | 6/100 [04:03<1:03:37, 40.61s/it]  7%|▋         | 7/100 [04:44<1:02:59, 40.64s/it]  8%|▊         | 8/100 [05:25<1:02:18, 40.64s/it]  9%|▉         | 9/100 [06:05<1:01:37, 40.63s/it] 10%|█         | 10/100 [06:46<1:00:53, 40.60s/it] 11%|█         | 11/100 [07:30<1:01:39, 41.57s/it] 12%|█▏        | 12/100 [08:13<1:01:56, 42.24s/it] 13%|█▎        | 13/100 [08:57<1:01:53, 42.69s/it] 14%|█▍        | 14/100 [09:41<1:01:38, 43.01s/it] 15%|█▌        | 15/100 [10:25<1:01:15, 43.24s/it] 16%|█▌        | 16/100 [11:08<1:00:45, 43.40s/it] 17%|█▋        | 17/100 [11:52<1:00:11, 43.51s/it] 18%|█▊        | 18/100 [12:36<59:36, 43.62s/it]   19%|█▉        | 19/100 [13:20<58:57, 43.67s/it] 20%|██        | 20/100 [14:04<58:16, 43.70s/it] 21%|██        | 21/100 [14:51<58:57, 44.77s/it] 22%|██▏       | 22/100 [15:38<59:08, 45.50s/it] 23%|██▎       | 23/100 [16:25<59:02, 46.01s/it] 24%|██▍       | 24/100 [17:12<58:43, 46.37s/it] 25%|██▌       | 25/100 [18:00<58:16, 46.62s/it] 26%|██▌       | 26/100 [18:47<57:42, 46.79s/it] 27%|██▋       | 27/100 [19:34<57:06, 46.94s/it] 28%|██▊       | 28/100 [20:21<56:25, 47.02s/it] 29%|██▉       | 29/100 [21:08<55:42, 47.07s/it] 30%|███       | 30/100 [21:56<54:57, 47.11s/it] 31%|███       | 31/100 [22:48<55:55, 48.64s/it] 32%|███▏      | 32/100 [23:40<56:19, 49.70s/it] 33%|███▎      | 33/100 [24:32<56:19, 50.44s/it] 34%|███▍      | 34/100 [25:24<56:03, 50.96s/it] 35%|███▌      | 35/100 [26:17<55:35, 51.32s/it] 36%|███▌      | 36/100 [27:09<55:00, 51.57s/it] 37%|███▋      | 37/100 [28:01<54:22, 51.79s/it] 38%|███▊      | 38/100 [28:53<53:38, 51.92s/it] 39%|███▉      | 39/100 [29:45<52:51, 51.99s/it] 40%|████      | 40/100 [30:38<52:02, 52.04s/it] 41%|████      | 41/100 [31:30<51:12, 52.08s/it] 42%|████▏     | 42/100 [32:22<50:21, 52.10s/it] 43%|████▎     | 43/100 [33:14<49:30, 52.12s/it] 44%|████▍     | 44/100 [34:06<48:39, 52.13s/it] 45%|████▌     | 45/100 [34:58<47:47, 52.14s/it] 46%|████▌     | 46/100 [35:51<46:56, 52.15s/it] 47%|████▋     | 47/100 [36:43<46:06, 52.20s/it] 48%|████▊     | 48/100 [37:35<45:14, 52.20s/it] 49%|████▉     | 49/100 [38:27<44:21, 52.19s/it] 50%|█████     | 50/100 [39:19<43:29, 52.18s/it] 51%|█████     | 51/100 [40:12<42:36, 52.18s/it] 52%|█████▏    | 52/100 [41:04<41:44, 52.17s/it] 53%|█████▎    | 53/100 [41:56<40:52, 52.18s/it] 54%|█████▍    | 54/100 [42:48<40:00, 52.18s/it] 55%|█████▌    | 55/100 [43:40<39:07, 52.18s/it] 56%|█████▌    | 56/100 [44:33<38:17, 52.21s/it] 57%|█████▋    | 57/100 [45:25<37:25, 52.21s/it] 58%|█████▊    | 58/100 [46:17<36:32, 52.20s/it] 59%|█████▉    | 59/100 [47:09<35:40, 52.20s/it] 60%|██████    | 60/100 [48:01<34:47, 52.19s/it] 61%|██████    | 61/100 [48:54<33:55, 52.19s/it] 62%|██████▏   | 62/100 [49:46<33:02, 52.18s/it] 63%|██████▎   | 63/100 [50:38<32:10, 52.17s/it] 64%|██████▍   | 64/100 [51:30<31:18, 52.17s/it] 65%|██████▌   | 65/100 [52:22<30:26, 52.17s/it] 66%|██████▌   | 66/100 [53:14<29:33, 52.18s/it] 67%|██████▋   | 67/100 [54:07<28:43, 52.22s/it] 68%|██████▊   | 68/100 [54:59<27:50, 52.22s/it] 69%|██████▉   | 69/100 [55:51<26:58, 52.20s/it] 70%|███████   | 70/100 [56:43<26:05, 52.20s/it] 71%|███████   | 71/100 [57:35<25:13, 52.19s/it] 72%|███████▏  | 72/100 [58:28<24:21, 52.19s/it] 73%|███████▎  | 73/100 [59:20<23:29, 52.19s/it] 74%|███████▍  | 74/100 [1:00:12<22:36, 52.19s/it] 75%|███████▌  | 75/100 [1:01:04<21:44, 52.19s/it] 76%|███████▌  | 76/100 [1:01:56<20:52, 52.19s/it] 77%|███████▋  | 77/100 [1:02:49<20:01, 52.22s/it] 78%|███████▊  | 78/100 [1:03:41<19:08, 52.23s/it] 79%|███████▉  | 79/100 [1:04:33<18:16, 52.22s/it] 80%|████████  | 80/100 [1:05:25<17:24, 52.21s/it] 81%|████████  | 81/100 [1:06:17<16:31, 52.20s/it] 82%|████████▏ | 82/100 [1:07:10<15:39, 52.20s/it] 83%|████████▎ | 83/100 [1:08:02<14:47, 52.20s/it] 84%|████████▍ | 84/100 [1:08:54<13:55, 52.19s/it] 85%|████████▌ | 85/100 [1:09:46<13:02, 52.19s/it] 86%|████████▌ | 86/100 [1:10:38<12:10, 52.18s/it] 87%|████████▋ | 87/100 [1:11:31<11:18, 52.21s/it] 88%|████████▊ | 88/100 [1:12:23<10:26, 52.22s/it] 89%|████████▉ | 89/100 [1:13:15<09:34, 52.21s/it] 90%|█████████ | 90/100 [1:14:07<08:42, 52.21s/it] 91%|█████████ | 91/100 [1:14:59<07:49, 52.20s/it] 92%|█████████▏| 92/100 [1:15:52<06:57, 52.20s/it] 93%|█████████▎| 93/100 [1:16:44<06:05, 52.20s/it] 94%|█████████▍| 94/100 [1:17:36<05:13, 52.20s/it] 95%|█████████▌| 95/100 [1:18:28<04:21, 52.20s/it] 96%|█████████▌| 96/100 [1:19:21<03:28, 52.23s/it] 97%|█████████▋| 97/100 [1:20:13<02:36, 52.22s/it] 98%|█████████▊| 98/100 [1:21:05<01:44, 52.21s/it] 99%|█████████▉| 99/100 [1:21:57<00:52, 52.21s/it]100%|██████████| 100/100 [1:22:49<00:00, 52.20s/it]100%|██████████| 100/100 [1:22:49<00:00, 49.70s/it]
Epoch 0 - Train Loss: 0.498499, Val Loss: 0.385310, mAP@.5:.95: 0.0000, mAP@.5: 0.0000
Epoch 1 - Train Loss: 0.323767, Val Loss: 0.299248, mAP@.5:.95: 0.0000, mAP@.5: 0.0000
Epoch 2 - Train Loss: 0.308852, Val Loss: 0.349314, mAP@.5:.95: 0.0000, mAP@.5: 0.0000
Epoch 3 - Train Loss: 0.303468, Val Loss: 0.311320, mAP@.5:.95: 0.0000, mAP@.5: 0.0000
Epoch 4 - Train Loss: 0.297628, Val Loss: 0.255102, mAP@.5:.95: 0.0000, mAP@.5: 0.0000
Epoch 5 - Train Loss: 0.292813, Val Loss: 0.365932, mAP@.5:.95: 0.0000, mAP@.5: 0.0000
Epoch 6 - Train Loss: 0.293593, Val Loss: 0.257365, mAP@.5:.95: 0.0000, mAP@.5: 0.0000
Epoch 7 - Train Loss: 0.290296, Val Loss: 0.211261, mAP@.5:.95: 0.0000, mAP@.5: 0.0000
Epoch 8 - Train Loss: 0.286248, Val Loss: 0.248905, mAP@.5:.95: 0.0000, mAP@.5: 0.0000
Epoch 9 - Train Loss: 0.286728, Val Loss: 0.230283, mAP@.5:.95: 0.0000, mAP@.5: 0.0000
Unfreezing layer 3. Cool party!
Epoch 10 - Train Loss: 0.278846, Val Loss: 0.256903, mAP@.5:.95: 0.0015, mAP@.5: 0.0099
Epoch 11 - Train Loss: 0.275463, Val Loss: 0.401338, mAP@.5:.95: 0.0039, mAP@.5: 0.0165
Epoch 12 - Train Loss: 0.275544, Val Loss: 0.277775, mAP@.5:.95: 0.0000, mAP@.5: 0.0000
Epoch 13 - Train Loss: 0.275585, Val Loss: 0.254376, mAP@.5:.95: 0.0054, mAP@.5: 0.0170
Epoch 14 - Train Loss: 0.272497, Val Loss: 0.272251, mAP@.5:.95: 0.0078, mAP@.5: 0.0288
Epoch 15 - Train Loss: 0.273968, Val Loss: 0.332695, mAP@.5:.95: 0.0054, mAP@.5: 0.0170
Epoch 16 - Train Loss: 0.273076, Val Loss: 0.244859, mAP@.5:.95: 0.0094, mAP@.5: 0.0225
Epoch 17 - Train Loss: 0.271344, Val Loss: 0.325729, mAP@.5:.95: 0.0077, mAP@.5: 0.0291
Epoch 18 - Train Loss: 0.269495, Val Loss: 0.307737, mAP@.5:.95: 0.0093, mAP@.5: 0.0243
Epoch 19 - Train Loss: 0.268722, Val Loss: 0.269972, mAP@.5:.95: 0.0106, mAP@.5: 0.0293
Unfreezing layer 2. What killed the dinosaurs? The Ice Age!
Epoch 20 - Train Loss: 0.266097, Val Loss: 0.302349, mAP@.5:.95: 0.0116, mAP@.5: 0.0460
Epoch 21 - Train Loss: 0.263954, Val Loss: 0.273855, mAP@.5:.95: 0.0136, mAP@.5: 0.0440
Epoch 22 - Train Loss: 0.265610, Val Loss: 0.204688, mAP@.5:.95: 0.0193, mAP@.5: 0.0468
Epoch 23 - Train Loss: 0.264825, Val Loss: 0.272720, mAP@.5:.95: 0.0107, mAP@.5: 0.0381
Epoch 24 - Train Loss: 0.264415, Val Loss: 0.225781, mAP@.5:.95: 0.0151, mAP@.5: 0.0460
Epoch 25 - Train Loss: 0.264681, Val Loss: 0.230529, mAP@.5:.95: 0.0096, mAP@.5: 0.0322
Epoch 26 - Train Loss: 0.263549, Val Loss: 0.248121, mAP@.5:.95: 0.0158, mAP@.5: 0.0455
Epoch 27 - Train Loss: 0.263051, Val Loss: 0.280473, mAP@.5:.95: 0.0140, mAP@.5: 0.0440
Epoch 28 - Train Loss: 0.263504, Val Loss: 0.368437, mAP@.5:.95: 0.0126, mAP@.5: 0.0450
Epoch 29 - Train Loss: 0.262443, Val Loss: 0.266136, mAP@.5:.95: 0.0166, mAP@.5: 0.0563
Unfreezing the entire backbone. Everybody chill!
Epoch 30 - Train Loss: 0.263291, Val Loss: 0.365384, mAP@.5:.95: 0.0123, mAP@.5: 0.0444
Epoch 31 - Train Loss: 0.262874, Val Loss: 0.228201, mAP@.5:.95: 0.0132, mAP@.5: 0.0442
Epoch 32 - Train Loss: 0.261846, Val Loss: 0.234390, mAP@.5:.95: 0.0134, mAP@.5: 0.0467
Epoch 33 - Train Loss: 0.261249, Val Loss: 0.200640, mAP@.5:.95: 0.0161, mAP@.5: 0.0512
Epoch 34 - Train Loss: 0.262749, Val Loss: 0.221440, mAP@.5:.95: 0.0104, mAP@.5: 0.0360
Epoch 35 - Train Loss: 0.261828, Val Loss: 0.306011, mAP@.5:.95: 0.0121, mAP@.5: 0.0440
Epoch 36 - Train Loss: 0.261308, Val Loss: 0.254685, mAP@.5:.95: 0.0116, mAP@.5: 0.0413
Epoch 37 - Train Loss: 0.260359, Val Loss: 0.227462, mAP@.5:.95: 0.0124, mAP@.5: 0.0419
Epoch 38 - Train Loss: 0.262234, Val Loss: 0.286087, mAP@.5:.95: 0.0140, mAP@.5: 0.0452
Epoch 39 - Train Loss: 0.260774, Val Loss: 0.253531, mAP@.5:.95: 0.0116, mAP@.5: 0.0419
Epoch 40 - Train Loss: 0.260793, Val Loss: 0.325649, mAP@.5:.95: 0.0110, mAP@.5: 0.0371
Epoch 41 - Train Loss: 0.263277, Val Loss: 0.251401, mAP@.5:.95: 0.0131, mAP@.5: 0.0463
Epoch 42 - Train Loss: 0.259803, Val Loss: 0.244353, mAP@.5:.95: 0.0123, mAP@.5: 0.0415
Epoch 43 - Train Loss: 0.263029, Val Loss: 0.330695, mAP@.5:.95: 0.0116, mAP@.5: 0.0405
Epoch 44 - Train Loss: 0.262638, Val Loss: 0.284023, mAP@.5:.95: 0.0115, mAP@.5: 0.0399
Epoch 45 - Train Loss: 0.260048, Val Loss: 0.313481, mAP@.5:.95: 0.0117, mAP@.5: 0.0398
Epoch 46 - Train Loss: 0.259672, Val Loss: 0.224991, mAP@.5:.95: 0.0147, mAP@.5: 0.0457
Epoch 47 - Train Loss: 0.261266, Val Loss: 0.345882, mAP@.5:.95: 0.0142, mAP@.5: 0.0443
Epoch 48 - Train Loss: 0.262175, Val Loss: 0.368474, mAP@.5:.95: 0.0146, mAP@.5: 0.0492
Epoch 49 - Train Loss: 0.262007, Val Loss: 0.330913, mAP@.5:.95: 0.0114, mAP@.5: 0.0407
Epoch 50 - Train Loss: 0.260925, Val Loss: 0.255491, mAP@.5:.95: 0.0112, mAP@.5: 0.0406
Epoch 51 - Train Loss: 0.262990, Val Loss: 0.242782, mAP@.5:.95: 0.0149, mAP@.5: 0.0438
Epoch 52 - Train Loss: 0.261379, Val Loss: 0.174945, mAP@.5:.95: 0.0150, mAP@.5: 0.0482
Epoch 53 - Train Loss: 0.261264, Val Loss: 0.257143, mAP@.5:.95: 0.0145, mAP@.5: 0.0459
Epoch 54 - Train Loss: 0.262060, Val Loss: 0.299366, mAP@.5:.95: 0.0122, mAP@.5: 0.0386
Epoch 55 - Train Loss: 0.260965, Val Loss: 0.234872, mAP@.5:.95: 0.0121, mAP@.5: 0.0383
Epoch 56 - Train Loss: 0.261792, Val Loss: 0.284430, mAP@.5:.95: 0.0121, mAP@.5: 0.0402
Epoch 57 - Train Loss: 0.262454, Val Loss: 0.294222, mAP@.5:.95: 0.0155, mAP@.5: 0.0458
Epoch 58 - Train Loss: 0.260830, Val Loss: 0.179950, mAP@.5:.95: 0.0126, mAP@.5: 0.0436
Epoch 59 - Train Loss: 0.260697, Val Loss: 0.294077, mAP@.5:.95: 0.0138, mAP@.5: 0.0483
Epoch 60 - Train Loss: 0.261163, Val Loss: 0.301717, mAP@.5:.95: 0.0132, mAP@.5: 0.0472
Epoch 61 - Train Loss: 0.262340, Val Loss: 0.251039, mAP@.5:.95: 0.0136, mAP@.5: 0.0458
Epoch 62 - Train Loss: 0.260265, Val Loss: 0.219414, mAP@.5:.95: 0.0144, mAP@.5: 0.0498
Epoch 63 - Train Loss: 0.262112, Val Loss: 0.220785, mAP@.5:.95: 0.0149, mAP@.5: 0.0457
Epoch 64 - Train Loss: 0.260212, Val Loss: 0.269739, mAP@.5:.95: 0.0159, mAP@.5: 0.0466
Epoch 65 - Train Loss: 0.260765, Val Loss: 0.314149, mAP@.5:.95: 0.0154, mAP@.5: 0.0495
Epoch 66 - Train Loss: 0.260605, Val Loss: 0.280746, mAP@.5:.95: 0.0183, mAP@.5: 0.0491
Epoch 67 - Train Loss: 0.260011, Val Loss: 0.252864, mAP@.5:.95: 0.0155, mAP@.5: 0.0499
Epoch 68 - Train Loss: 0.260731, Val Loss: 0.231149, mAP@.5:.95: 0.0151, mAP@.5: 0.0462
Epoch 69 - Train Loss: 0.261904, Val Loss: 0.348219, mAP@.5:.95: 0.0147, mAP@.5: 0.0448
Epoch 70 - Train Loss: 0.260467, Val Loss: 0.276939, mAP@.5:.95: 0.0137, mAP@.5: 0.0420
Epoch 71 - Train Loss: 0.261971, Val Loss: 0.254056, mAP@.5:.95: 0.0166, mAP@.5: 0.0516
Epoch 72 - Train Loss: 0.260922, Val Loss: 0.251041, mAP@.5:.95: 0.0143, mAP@.5: 0.0492
Epoch 73 - Train Loss: 0.260874, Val Loss: 0.305318, mAP@.5:.95: 0.0143, mAP@.5: 0.0471
Epoch 74 - Train Loss: 0.260915, Val Loss: 0.241195, mAP@.5:.95: 0.0151, mAP@.5: 0.0501
Epoch 75 - Train Loss: 0.260636, Val Loss: 0.220841, mAP@.5:.95: 0.0167, mAP@.5: 0.0521
Epoch 76 - Train Loss: 0.262382, Val Loss: 0.287660, mAP@.5:.95: 0.0157, mAP@.5: 0.0522
Epoch 77 - Train Loss: 0.259726, Val Loss: 0.181993, mAP@.5:.95: 0.0155, mAP@.5: 0.0447
Epoch 78 - Train Loss: 0.262158, Val Loss: 0.310306, mAP@.5:.95: 0.0139, mAP@.5: 0.0461
Epoch 79 - Train Loss: 0.260628, Val Loss: 0.301822, mAP@.5:.95: 0.0203, mAP@.5: 0.0578
Epoch 80 - Train Loss: 0.262367, Val Loss: 0.310289, mAP@.5:.95: 0.0169, mAP@.5: 0.0531
Epoch 81 - Train Loss: 0.263324, Val Loss: 0.219815, mAP@.5:.95: 0.0186, mAP@.5: 0.0568
Epoch 82 - Train Loss: 0.259758, Val Loss: 0.172502, mAP@.5:.95: 0.0145, mAP@.5: 0.0491
Epoch 83 - Train Loss: 0.259761, Val Loss: 0.241650, mAP@.5:.95: 0.0160, mAP@.5: 0.0448
Epoch 84 - Train Loss: 0.261134, Val Loss: 0.264210, mAP@.5:.95: 0.0166, mAP@.5: 0.0585
Epoch 85 - Train Loss: 0.262084, Val Loss: 0.299275, mAP@.5:.95: 0.0167, mAP@.5: 0.0496
Epoch 86 - Train Loss: 0.260670, Val Loss: 0.261811, mAP@.5:.95: 0.0145, mAP@.5: 0.0508
Epoch 87 - Train Loss: 0.260456, Val Loss: 0.302736, mAP@.5:.95: 0.0186, mAP@.5: 0.0499
Epoch 88 - Train Loss: 0.261159, Val Loss: 0.251813, mAP@.5:.95: 0.0142, mAP@.5: 0.0460
Epoch 89 - Train Loss: 0.261388, Val Loss: 0.273306, mAP@.5:.95: 0.0131, mAP@.5: 0.0461
Epoch 90 - Train Loss: 0.260293, Val Loss: 0.247416, mAP@.5:.95: 0.0146, mAP@.5: 0.0487
Epoch 91 - Train Loss: 0.261538, Val Loss: 0.271706, mAP@.5:.95: 0.0143, mAP@.5: 0.0497
Epoch 92 - Train Loss: 0.259793, Val Loss: 0.229781, mAP@.5:.95: 0.0141, mAP@.5: 0.0469
Epoch 93 - Train Loss: 0.260495, Val Loss: 0.278370, mAP@.5:.95: 0.0147, mAP@.5: 0.0501
Epoch 94 - Train Loss: 0.260493, Val Loss: 0.300977, mAP@.5:.95: 0.0168, mAP@.5: 0.0518
Epoch 95 - Train Loss: 0.260847, Val Loss: 0.282826, mAP@.5:.95: 0.0154, mAP@.5: 0.0505
Epoch 96 - Train Loss: 0.261060, Val Loss: 0.263202, mAP@.5:.95: 0.0161, mAP@.5: 0.0510
Epoch 97 - Train Loss: 0.259651, Val Loss: 0.284040, mAP@.5:.95: 0.0165, mAP@.5: 0.0546
Epoch 98 - Train Loss: 0.261163, Val Loss: 0.226926, mAP@.5:.95: 0.0157, mAP@.5: 0.0505
Epoch 99 - Train Loss: 0.260791, Val Loss: 0.252850, mAP@.5:.95: 0.0165, mAP@.5: 0.0497
Dragoooo! Dragooooooo! Dragoooooooooooo!
tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
       device='cuda:0') tensor([0.1769, 0.1563, 0.1409, 0.1375, 0.1198, 0.1153, 0.1125, 0.1113, 0.1039,
        0.1038, 0.0982, 0.0973, 0.0877, 0.0850, 0.0805, 0.0763, 0.0746, 0.0732,
        0.0719, 0.0687, 0.0669, 0.0664, 0.0626, 0.0619, 0.0615, 0.0613, 0.0586,
        0.0585, 0.0581, 0.0576, 0.0575, 0.0574, 0.0559, 0.0553, 0.0549, 0.0546,
        0.0532, 0.0528, 0.0527, 0.0520, 0.0511, 0.0509, 0.0509, 0.0507, 0.0506,
        0.0505, 0.0503, 0.0500], device='cuda:0')
tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1], device='cuda:0') tensor([0.5244, 0.3605, 0.3345, 0.2661, 0.2527, 0.2343, 0.2071, 0.1929, 0.1891,
        0.1553, 0.1507, 0.1486, 0.1389, 0.1325, 0.1288, 0.1237, 0.1215, 0.1200,
        0.1195, 0.1101, 0.1080, 0.1062, 0.1048, 0.0969, 0.0941, 0.0883, 0.0871,
        0.0825, 0.0820, 0.0807, 0.0802, 0.0795, 0.0791, 0.0790, 0.0770, 0.0766,
        0.0755, 0.0751, 0.0747, 0.0737, 0.0729, 0.0728, 0.0715, 0.0702, 0.0701,
        0.0688, 0.0680, 0.0675, 0.0653, 0.0648, 0.0634, 0.0630, 0.0627, 0.0619,
        0.0615, 0.0615, 0.0610, 0.0606, 0.0602, 0.0600, 0.0599, 0.0589, 0.0588,
        0.0560, 0.0541, 0.0537, 0.0536, 0.0532, 0.0531, 0.0526, 0.0521, 0.0519,
        0.0509, 0.0504, 0.0503, 0.0500], device='cuda:0')
IoU Matrix:
 tensor([], size=(0, 1))
mAP at IoU=0.50:0.95:  tensor(0.0165)
mAP at IoU=0.50:  tensor(0.0497)
No true positives detected — precision/recall not available.
Recall not available — likely no matched predictions.
Inference complete and results saved!
